{"nbformat_minor": 1, "cells": [{"source": "## Tuning Model Parameters\n\nIn this exercise, you will optimise the parameters for a classification model.\n\n### Prepare the Data\n\nFirst, import the libraries you will need and prepare the training and test data:", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 1, "cell_type": "code", "source": "# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Load the source data\ncsv = spark.read.csv('wasb:///data/flights.csv', inferSchema=True, header=True)\n\n# Select features and label\ndata = csv.select(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"label\")))\n\n# Split the data\nsplits = data.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1613740567063_0005</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-rayspa.pk5nseqskssevkfuqghr2123nc.ix.internal.cloudapp.net:8088/proxy/application_1613740567063_0005/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn1-rayspa.pk5nseqskssevkfuqghr2123nc.ix.internal.cloudapp.net:30060/node/containerlogs/container_1613740567063_0005_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n"}], "metadata": {"scrolled": false, "cell_status": {"execute_time": {"duration": 46510.81396484375, "end_time": 1613743977619.876}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### Define the Pipeline\nNow define a pipeline that creates a feature vector and trains a classification model", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 2, "cell_type": "code", "source": "# Define the pipeline\nassembler = VectorAssembler(inputCols = [\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"], outputCol=\"features\")\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\npipeline = Pipeline(stages=[assembler, lr])", "outputs": [], "metadata": {"scrolled": false, "cell_status": {"execute_time": {"duration": 414.429931640625, "end_time": 1613744041311.508}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### Tune Parameters\nYou can tune parameters to find the best model for your data. A simple way to do this is to use  **TrainValidationSplit** to evaluate each combination of parameters defined in a **ParameterGrid** against a subset of the training data in order to find the best performing parameters.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 3, "cell_type": "code", "source": "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1, 0.01]).addGrid(lr.maxIter, [10, 5]).addGrid(lr.threshold, [0.35, 0.30]).build()\ntvs = TrainValidationSplit(estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n\nmodel = tvs.fit(train)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 526266.0739746094, "end_time": 1613744570958.048}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### Test the Model\nNow you're ready to apply the model to the test data.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 4, "cell_type": "code", "source": "prediction = model.transform(test)\npredicted = prediction.select(\"features\", \"prediction\", \"probability\", \"trueLabel\")\npredicted.show(100)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------------+----------+--------------------+---------+\n|            features|prediction|         probability|trueLabel|\n+--------------------+----------+--------------------+---------+\n|[1.0,1.0,10140.0,...|       0.0|[0.91750935817645...|        0|\n|[1.0,1.0,10140.0,...|       1.0|[0.02297766998321...|        1|\n|[1.0,1.0,10140.0,...|       0.0|[0.92527486189785...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.9140267567544,...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.90126618543458...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.89427272404513...|        0|\n|[1.0,1.0,10140.0,...|       1.0|[0.36987876104031...|        1|\n|[1.0,1.0,10140.0,...|       0.0|[0.90794419409532...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.87075620504795...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.86193273617935...|        0|\n|[1.0,1.0,10140.0,...|       1.0|[0.61286736637627...|        1|\n|[1.0,1.0,10140.0,...|       0.0|[0.94778740439958...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.94388394055568...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.93046830583974...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.92537200042878...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.90796226884704...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.90139120779210...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.89440556438726...|        0|\n|[1.0,1.0,10140.0,...|       1.0|[0.38814747698489...|        1|\n|[1.0,1.0,10140.0,...|       0.0|[0.92774610978429...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.92774610978429...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.85696639771866...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.92301168713475...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.91264385486495...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.89970055005053...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.95055864894363...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.89369296132965...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.89378880973442...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.91434712129915...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.94075503239378...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.92664950150344...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.93674024508125...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.93207007871144...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.92175833955493...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.91608121637595...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.89674590998454...|        0|\n|[1.0,1.0,10140.0,...|       1.0|[7.35569358640266...|        1|\n|[1.0,1.0,10140.0,...|       0.0|[0.94224197928531...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.84917718511379...|        0|\n|[1.0,1.0,10140.0,...|       0.0|[0.93834846359201...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.94013150819008...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.95250691934616...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.95603145738982...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.93691975392373...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.96291091662682...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.94263725769219...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.93837379900669...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.93381570946562...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.93381570946562...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.91229102780367...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.91229102780367...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.90599702295634...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.90599702295634...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.85916329209900...|        0|\n|[1.0,1.0,10299.0,...|       0.0|[0.81808947311153...|        1|\n|[1.0,1.0,10299.0,...|       1.0|[0.26659302417442...|        1|\n|[1.0,1.0,10299.0,...|       0.0|[0.92923572889627...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.89833449250793...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91225669019862...|        1|\n|[1.0,1.0,10397.0,...|       0.0|[0.90596047527910...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.90596047527910...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.76819134352648...|        0|\n|[1.0,1.0,10397.0,...|       1.0|[0.28167234672128...|        1|\n|[1.0,1.0,10397.0,...|       0.0|[0.91845604721833...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91845604721833...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.92439999992168...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91889768763712...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91303258260895...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.90678635464706...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.88557695991082...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91897287136981...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91897287136981...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.90023125644650...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.90023125644650...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.89317317839870...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.78331553223000...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.77009860799006...|        0|\n|[1.0,1.0,10397.0,...|       1.0|[0.51636636702889...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.92464900505847...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91916323102002...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91916323102002...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.89341712028829...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.69641854871973...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.92472180318206...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.92472180318206...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91924086616465...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91339823994429...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91339823994429...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.90717560445018...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.89351661733276...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.86083886905900...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.83112185791094...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.66349217274503...|        0|\n|[1.0,1.0,10397.0,...|       1.0|[0.55516055965441...|        0|\n|[1.0,1.0,10397.0,...|       1.0|[0.51726648082558...|        0|\n|[1.0,1.0,10397.0,...|       1.0|[0.49821703656034...|        1|\n|[1.0,1.0,10397.0,...|       1.0|[1.89123770644808...|        1|\n|[1.0,1.0,10397.0,...|       0.0|[0.91983026875216...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91402629555193...|        0|\n|[1.0,1.0,10397.0,...|       0.0|[0.91402629555193...|        0|\n+--------------------+----------+--------------------+---------+\nonly showing top 100 rows"}], "metadata": {"scrolled": false, "cell_status": {"execute_time": {"duration": 14001.20703125, "end_time": 1613744739861.787}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### Compute Confusion Matrix Metrics\nClassifiers are typically evaluated by creating a *confusion matrix*, which indicates the number of:\n- True Positives\n- True Negatives\n- False Positives\n- False Negatives\n\nFrom these core measures, other evaluation metrics such as *precision* and *recall* can be calculated.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 5, "cell_type": "code", "source": "tp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\nfp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\ntn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\nfn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\nmetrics = spark.createDataFrame([\n (\"TP\", tp),\n (\"FP\", fp),\n (\"TN\", tn),\n (\"FN\", fn),\n (\"Precision\", tp / (tp + fp)),\n (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\nmetrics.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+---------+------------------+\n|   metric|             value|\n+---------+------------------+\n|       TP|          112904.0|\n|       FP|           11366.0|\n|       TN|          637951.0|\n|       FN|           48236.0|\n|Precision|0.9085378611088758|\n|   Recall|0.7006578130817922|\n+---------+------------------+"}], "metadata": {"cell_status": {"execute_time": {"duration": 84592.48999023438, "end_time": 1613746319252.356}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "### Review the Area Under ROC\nAnother way to assess the performance of a classification model is to measure the area under a ROC curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that you can use to compute this.", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 6, "cell_type": "code", "source": "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\naur = evaluator.evaluate(prediction)\nprint \"AUR = \", aur", "outputs": [{"output_type": "stream", "name": "stdout", "text": "AUR =  0.841576632998"}], "metadata": {"cell_status": {"execute_time": {"duration": 21861.43603515625, "end_time": 1613746514895.516}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}